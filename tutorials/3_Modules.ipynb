{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7b7556-f8df-4e50-801b-7e215e46a415",
   "metadata": {},
   "source": [
    "## Using modules with VPRTempo and VPRTempoQuant\n",
    "\n",
    "### By Adam D Hines (https://research.qut.edu.au/qcr/people/adam-hines/)\n",
    "\n",
    "VPRTempo is based on the following paper, if you use or find this code helpful for your research please consider citing the source:\n",
    "    \n",
    "[Adam D Hines, Peter G Stratton, Michael Milford, & Tobias Fischer. \"VPRTempo: A Fast Temporally Encoded Spiking Neural Network for Visual Place Recognition. arXiv September 2023](https://arxiv.org/abs/2309.10225)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this tutorial, we will go through how to use modules with VPRTempo. Modules break up the training data into multiple networks, which has been shown to [improve the overall performance](https://towardsdatascience.com/machine-learning-with-expert-models-a-primer-6c74585f223f) and accuracy of larger models.\n",
    "\n",
    "Before starting, make sure you have [installed the dependencies](https://github.com/AdamDHines/VPRTempo-quant#installation-and-setup) and/or activated the conda environment. You will also need the [Nordland](https://github.com/AdamDHines/VPRTempo-quant#nordland) dataset before proceeding, as this tutorial will cover training the network using this as an example.\n",
    "\n",
    "### Comparing results using expert modules for VPRTempo\n",
    "\n",
    "Let's start by training the base model with 1000 places, which is 500 more than the default settings. We will need to parse the `--train_new_model`, `--num_places`, as well as another argument we haven't seen yet `--max_module`. \n",
    "\n",
    "`--max_module` tells the network how many places each expert module should learn, which by default is set to `500`. So if we're training a new, singular network with 1000 places we need to increase `max_module` to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d1a7b-8788-436a-8dd5-27f60077c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the working directory to the main folder from tutorials\n",
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0981001-fa1c-49e0-bbe3-e5a628098eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single network with 1000 places\n",
    "!python main.py --num_places 1000 --max_module 1000 --train_new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8287b-b47b-4f7e-9d1c-4b309746b284",
   "metadata": {},
   "source": [
    "Now let's see how this performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32435d47-e583-4768-86ed-2998ec78fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the inferencing network on the singular 1000 place trained model\n",
    "!python main.py --num_places 1000 --max_module 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845764ee-1492-449c-9816-a45ccfe043a1",
   "metadata": {},
   "source": [
    "Performance here is still pretty good, but let's see if we can improve it by splitting up the network into modules!\n",
    "\n",
    "Now that splitting up our 1000 place network into 2 networks, we can remove the `--max_module` argument because the default is set to 500. Instead what we will parse is `--num_modules` to tell the network to split things up into two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf368b-2f7f-4345-b882-7bf51622c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new 1000 place model with 2 modules\n",
    "!python main.py --num_places 1000 --num_modules 2 --train_new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce9e04-ff62-45ce-83b3-89e4623f0fd1",
   "metadata": {},
   "source": [
    "Now let's see how it compares with the singular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec3ec7-cca7-45a0-906b-cc3e6d14b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the network with 2 modules\n",
    "!python main.py --num_places 1000 --num_modules 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da07161-81e9-4773-90f1-e9d675e8c071",
   "metadata": {},
   "source": [
    "A modest boost to performance, however you have to imagine how this scales to much larger networks - especially when considering training times. Because the output layer is one-hot encoded, you need to increase the number of output neurons with each place you want to learn. Splitting up networks has a key benefit for VPRTempo to reduce overall training times with little impact on inference speeds. \n",
    "\n",
    "(Optional) Run a single network for 2500 places or 5 expert modules for 500 places each (reduced dimensionality to speed things up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd18263-190c-47f4-a37f-130a040d7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run a 2500 place comparison for singular vs modular networks\n",
    "# Train networks\n",
    "!python main.py --num_places 2500 --max_module 2500 --dims 28,28 --patches 7 --train_new_model\n",
    "!python main.py --num_places 2500 --num_modules 5 --dims 28,28 --patches 7 --train_new_model\n",
    "# Run inference\n",
    "!python main.py --num_places 2500 --max_module 2500 --dims 28,28 --patches 7\n",
    "!python main.py --num_places 2500 --num_modules 5 --dims 28,28 --patches 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02edb3da-9d34-4709-950d-d202c5e902e7",
   "metadata": {},
   "source": [
    "As in the other tutorials, parsing the `--quantize` argument will run exactly the same but for VPRTempoQuant. Let's do a quick comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e520f0a-7b6f-4546-8169-14f20f2f9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train networks\n",
    "#!python main.py --num_places 1500 --max_module 1500 --dims 28,28 --patches 7 --train_new_model --quantize\n",
    "#!python main.py --num_places 1500 --num_modules 3 --dims 28,28 --patches 7 --train_new_model --quantize\n",
    "# Run inference\n",
    "!python main.py --num_places 1500 --max_module 1500 --dims 28,28 --patches 7 --quantize\n",
    "!python main.py --num_places 1500 --num_modules 3 --dims 28,28 --patches 7 --quantize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58581b5c-70a8-4708-bda1-1ccca1edc70b",
   "metadata": {},
   "source": [
    "Once again, we can see that whilst there's a modest boost to the accuracy result the clear improve is the training speed. Because each network is smaller, the opeations on CPU are a lot less computationally heavy when splitting the networks up.\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "This tutorial provided a simple overview of how you can train network models using expert modules. \n",
    "\n",
    "If you would like to go more in-depth, checkout some of the [other tutorials](https://github.com/AdamDHines/VPRTempo-quant/tree/main/tutorials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309b80b-05c2-4577-8ea0-2e45bf2d6aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
